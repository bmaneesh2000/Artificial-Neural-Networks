{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WBd69MDEm4rF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-16 13:54:26.142577: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "kycWuRI9oaSP"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.12.0'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pD_55cOxLkAb"
      },
      "outputs": [],
      "source": [
        "path_to_file = 'shakespeare.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "aavnuByVymwK"
      },
      "outputs": [],
      "source": [
        "text = open(path_to_file, 'r').read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IlCgQBRVymwR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '}']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(vocab)\n",
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IalZLbvOzf-F"
      },
      "outputs": [],
      "source": [
        "char_to_ind = {u:i for i, u in enumerate(vocab)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "fmmP5iCwm4rp"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " '(': 6,\n",
              " ')': 7,\n",
              " ',': 8,\n",
              " '-': 9,\n",
              " '.': 10,\n",
              " '0': 11,\n",
              " '1': 12,\n",
              " '2': 13,\n",
              " '3': 14,\n",
              " '4': 15,\n",
              " '5': 16,\n",
              " '6': 17,\n",
              " '7': 18,\n",
              " '8': 19,\n",
              " '9': 20,\n",
              " ':': 21,\n",
              " ';': 22,\n",
              " '<': 23,\n",
              " '>': 24,\n",
              " '?': 25,\n",
              " 'A': 26,\n",
              " 'B': 27,\n",
              " 'C': 28,\n",
              " 'D': 29,\n",
              " 'E': 30,\n",
              " 'F': 31,\n",
              " 'G': 32,\n",
              " 'H': 33,\n",
              " 'I': 34,\n",
              " 'J': 35,\n",
              " 'K': 36,\n",
              " 'L': 37,\n",
              " 'M': 38,\n",
              " 'N': 39,\n",
              " 'O': 40,\n",
              " 'P': 41,\n",
              " 'Q': 42,\n",
              " 'R': 43,\n",
              " 'S': 44,\n",
              " 'T': 45,\n",
              " 'U': 46,\n",
              " 'V': 47,\n",
              " 'W': 48,\n",
              " 'X': 49,\n",
              " 'Y': 50,\n",
              " 'Z': 51,\n",
              " '[': 52,\n",
              " ']': 53,\n",
              " '_': 54,\n",
              " '`': 55,\n",
              " 'a': 56,\n",
              " 'b': 57,\n",
              " 'c': 58,\n",
              " 'd': 59,\n",
              " 'e': 60,\n",
              " 'f': 61,\n",
              " 'g': 62,\n",
              " 'h': 63,\n",
              " 'i': 64,\n",
              " 'j': 65,\n",
              " 'k': 66,\n",
              " 'l': 67,\n",
              " 'm': 68,\n",
              " 'n': 69,\n",
              " 'o': 70,\n",
              " 'p': 71,\n",
              " 'q': 72,\n",
              " 'r': 73,\n",
              " 's': 74,\n",
              " 't': 75,\n",
              " 'u': 76,\n",
              " 'v': 77,\n",
              " 'w': 78,\n",
              " 'x': 79,\n",
              " 'y': 80,\n",
              " 'z': 81,\n",
              " '|': 82,\n",
              " '}': 83}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "char_to_ind"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "30ZYaWAOm4rt"
      },
      "outputs": [],
      "source": [
        "ind_to_char = np.array(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_6JPOWwJm4rz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1',\n",
              "       '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?',\n",
              "       'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
              "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
              "       '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i',\n",
              "       'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v',\n",
              "       'w', 'x', 'y', 'z', '|', '}'], dtype='<U1')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ind_to_char"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3fhOqV0lm4r2"
      },
      "outputs": [],
      "source": [
        "encoded_text = np.array([char_to_ind[c] for c in text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "axOX7rFom4r5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0,  1,  1, ..., 30, 39, 29])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoded_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0UHJDA39zf-O"
      },
      "outputs": [],
      "source": [
        "seq_len = 120"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7VRSK4cOm4sZ"
      },
      "outputs": [],
      "source": [
        "total_num_seq = len(text)//(seq_len+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xtW0jbbvm4sc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "45005"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_num_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ciatnowvm4se"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-16 13:54:43.688797: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
            "2023-09-16 13:54:44.478273: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [5445609]\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "1\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "F\n",
            "r\n",
            "o\n",
            "m\n",
            " \n",
            "f\n",
            "a\n",
            "i\n",
            "r\n",
            "e\n",
            "s\n",
            "t\n",
            " \n",
            "c\n",
            "r\n",
            "e\n",
            "a\n",
            "t\n",
            "u\n",
            "r\n",
            "e\n",
            "s\n",
            " \n",
            "w\n",
            "e\n",
            " \n",
            "d\n",
            "e\n",
            "s\n",
            "i\n",
            "r\n",
            "e\n",
            " \n",
            "i\n",
            "n\n",
            "c\n",
            "r\n",
            "e\n",
            "a\n",
            "s\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "a\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            "r\n",
            "e\n",
            "b\n",
            "y\n",
            " \n",
            "b\n",
            "e\n",
            "a\n",
            "u\n",
            "t\n",
            "y\n",
            "'\n",
            "s\n",
            " \n",
            "r\n",
            "o\n",
            "s\n",
            "e\n",
            " \n",
            "m\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "n\n",
            "e\n",
            "v\n",
            "e\n",
            "r\n",
            " \n",
            "d\n",
            "i\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "B\n",
            "u\n",
            "t\n",
            " \n",
            "a\n",
            "s\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "r\n",
            "i\n",
            "p\n",
            "e\n",
            "r\n",
            " \n",
            "s\n",
            "h\n",
            "o\n",
            "u\n",
            "l\n",
            "d\n",
            " \n",
            "b\n",
            "y\n",
            " \n",
            "t\n",
            "i\n",
            "m\n",
            "e\n",
            " \n",
            "d\n",
            "e\n",
            "c\n",
            "e\n",
            "a\n",
            "s\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "H\n",
            "i\n",
            "s\n",
            " \n",
            "t\n",
            "e\n",
            "n\n",
            "d\n",
            "e\n",
            "r\n",
            " \n",
            "h\n",
            "e\n",
            "i\n",
            "r\n",
            " \n",
            "m\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "b\n",
            "e\n",
            "a\n",
            "r\n",
            " \n",
            "h\n",
            "i\n",
            "s\n",
            " \n",
            "m\n",
            "e\n",
            "m\n",
            "o\n",
            "r\n",
            "y\n",
            ":\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "B\n",
            "u\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "o\n",
            "u\n",
            " \n",
            "c\n",
            "o\n",
            "n\n",
            "t\n",
            "r\n",
            "a\n",
            "c\n",
            "t\n",
            "e\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "o\n",
            "w\n",
            "n\n",
            " \n",
            "b\n",
            "r\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "e\n",
            "y\n",
            "e\n",
            "s\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "F\n",
            "e\n",
            "e\n",
            "d\n",
            "'\n",
            "s\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "l\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            "'\n",
            "s\n",
            " \n",
            "f\n",
            "l\n",
            "a\n",
            "m\n",
            "e\n",
            " \n",
            "w\n",
            "i\n",
            "t\n",
            "h\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            "-\n",
            "s\n",
            "u\n",
            "b\n",
            "s\n",
            "t\n",
            "a\n",
            "n\n",
            "t\n",
            "i\n",
            "a\n",
            "l\n",
            " \n",
            "f\n",
            "u\n",
            "e\n",
            "l\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "M\n",
            "a\n",
            "k\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "a\n",
            " \n",
            "f\n",
            "a\n",
            "m\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "w\n",
            "h\n",
            "e\n",
            "r\n",
            "e\n",
            " \n",
            "a\n",
            "b\n",
            "u\n",
            "n\n",
            "d\n",
            "a\n",
            "n\n",
            "c\n",
            "e\n",
            " \n",
            "l\n",
            "i\n",
            "e\n",
            "s\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "y\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "f\n",
            "o\n",
            "e\n",
            ",\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "s\n",
            "w\n",
            "e\n",
            "e\n",
            "t\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            " \n",
            "t\n",
            "o\n",
            "o\n",
            " \n",
            "c\n",
            "r\n",
            "u\n",
            "e\n",
            "l\n",
            ":\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "o\n",
            "u\n",
            " \n",
            "t\n",
            "h\n",
            "a\n",
            "t\n",
            " \n",
            "a\n",
            "r\n",
            "t\n",
            " \n",
            "n\n",
            "o\n",
            "w\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "o\n",
            "r\n",
            "l\n",
            "d\n",
            "'\n",
            "s\n",
            " \n",
            "f\n",
            "r\n",
            "e\n",
            "s\n",
            "h\n",
            " \n",
            "o\n",
            "r\n",
            "n\n",
            "a\n",
            "m\n",
            "e\n",
            "n\n",
            "t\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "A\n",
            "n\n",
            "d\n",
            " \n",
            "o\n",
            "n\n",
            "l\n",
            "y\n",
            " \n",
            "h\n",
            "e\n",
            "r\n",
            "a\n",
            "l\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "g\n",
            "a\n",
            "u\n",
            "d\n",
            "y\n",
            " \n",
            "s\n",
            "p\n",
            "r\n",
            "i\n",
            "n\n",
            "g\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "W\n",
            "i\n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "o\n",
            "w\n",
            "n\n",
            " \n",
            "b\n",
            "u\n"
          ]
        }
      ],
      "source": [
        "# Create Training Sequences\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
        "\n",
        "for i in char_dataset.take(500):\n",
        "     print(ind_to_char[i.numpy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "l4hkDU3i7ozi"
      },
      "outputs": [],
      "source": [
        "sequences = char_dataset.batch(seq_len+1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9NGu-FkO_kYU"
      },
      "outputs": [],
      "source": [
        "def create_seq_targets(seq):\n",
        "    input_txt = seq[:-1]\n",
        "    target_txt = seq[1:]\n",
        "    return input_txt, target_txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "HszljTg8m4so"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(create_seq_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "JkPa7AMrm4sq"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-16 13:54:45.633918: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [5445609]\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
            "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
            "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
            " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
            " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But\n",
            "\n",
            "\n",
            "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
            "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
            " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
            " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
            "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But \n"
          ]
        }
      ],
      "source": [
        "for input_txt, target_txt in  dataset.take(1):\n",
        "    print(input_txt.numpy())\n",
        "    print(''.join(ind_to_char[input_txt.numpy()]))\n",
        "    print('\\n')\n",
        "    print(target_txt.numpy())\n",
        "    # There is an extra whitespace!\n",
        "    print(''.join(ind_to_char[target_txt.numpy()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "p2pGotuNzf-S"
      },
      "outputs": [],
      "source": [
        "# Batch size\n",
        "batch_size = 128\n",
        "\n",
        "# Buffer size to shuffle the dataset so it doesn't attempt to shuffle\n",
        "# the entire sequence in memory. Instead, it maintains a buffer in which it shuffles elements\n",
        "buffer_size = 10000\n",
        "\n",
        "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gmcCALymm4su"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(128, 120), dtype=tf.int64, name=None), TensorSpec(shape=(128, 120), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zHT8cLh7EAsg"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embed_dim = 64\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_neurons = 1026"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YeRlEXgym4s1"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout,GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "VoFVGKlNkJfW"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.losses import sparse_categorical_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sblCzZoslZKH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function sparse_categorical_crossentropy in module keras.losses:\n",
            "\n",
            "sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1, ignore_class=None)\n",
            "    Computes the sparse categorical crossentropy loss.\n",
            "    \n",
            "    Standalone usage:\n",
            "    \n",
            "    >>> y_true = [1, 2]\n",
            "    >>> y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
            "    >>> loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
            "    >>> assert loss.shape == (2,)\n",
            "    >>> loss.numpy()\n",
            "    array([0.0513, 2.303], dtype=float32)\n",
            "    \n",
            "    >>> y_true = [[[ 0,  2],\n",
            "    ...            [-1, -1]],\n",
            "    ...           [[ 0,  2],\n",
            "    ...            [-1, -1]]]\n",
            "    >>> y_pred = [[[[1.0, 0.0, 0.0], [0.0, 0.0, 1.0]],\n",
            "    ...             [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]]],\n",
            "    ...           [[[1.0, 0.0, 0.0], [0.0, 0.5, 0.5]],\n",
            "    ...            [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]]]]\n",
            "    >>> loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
            "    ...   y_true, y_pred, ignore_class=-1)\n",
            "    >>> loss.numpy()\n",
            "    array([[[2.3841855e-07, 2.3841855e-07],\n",
            "            [0.0000000e+00, 0.0000000e+00]],\n",
            "           [[2.3841855e-07, 6.9314730e-01],\n",
            "            [0.0000000e+00, 0.0000000e+00]]], dtype=float32)\n",
            "    \n",
            "    Args:\n",
            "      y_true: Ground truth values.\n",
            "      y_pred: The predicted values.\n",
            "      from_logits: Whether `y_pred` is expected to be a logits tensor. By\n",
            "        default, we assume that `y_pred` encodes a probability distribution.\n",
            "      axis: Defaults to -1. The dimension along which the entropy is\n",
            "        computed.\n",
            "      ignore_class: Optional integer. The ID of a class to be ignored during\n",
            "        loss computation. This is useful, for example, in segmentation\n",
            "        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n",
            "        maps. By default (`ignore_class=None`), all classes are considered.\n",
            "    \n",
            "    Returns:\n",
            "      Sparse categorical crossentropy loss value.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(sparse_categorical_crossentropy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FrOOK61Olm1C"
      },
      "outputs": [],
      "source": [
        "def sparse_cat_loss(y_true,y_pred):\n",
        "  return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MtCrdfzEI2N0"
      },
      "outputs": [],
      "source": [
        "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, embed_dim,batch_input_shape=[batch_size, None]))\n",
        "    model.add(GRU(rnn_neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n",
        "    # Final Dense Layer to Predict\n",
        "    model.add(Dense(vocab_size))\n",
        "    model.compile(optimizer='adam', loss=sparse_cat_loss) \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wwsrpOik5zhv"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-16 13:54:50.169385: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-09-16 13:54:50.173263: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-09-16 13:54:50.175018: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
          ]
        }
      ],
      "source": [
        "model = create_model(\n",
        "  vocab_size = vocab_size,\n",
        "  embed_dim=embed_dim,\n",
        "  rnn_neurons=rnn_neurons,\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "liXuTFYMm4s6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (128, None, 64)           5376      \n",
            "                                                                 \n",
            " gru (GRU)                   (128, None, 1026)         3361176   \n",
            "                                                                 \n",
            " dense (Dense)               (128, None, 84)           86268     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,452,820\n",
            "Trainable params: 3,452,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "A4ygvfHn-wan"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-16 13:54:50.588019: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [5445609]\n",
            "\t [[{{node Placeholder/_0}}]]\n",
            "2023-09-16 13:54:50.588994: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [5445609]\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(128, 120, 84)  <=== (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "\n",
        "  # Predict off some random batch\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "\n",
        "  # Display the dimensions of the predictions\n",
        "  print(example_batch_predictions.shape, \" <=== (batch_size, sequence_length, vocab_size)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5ld8z3LPBAuv"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128, 120, 84), dtype=float32, numpy=\n",
              "array([[[ 8.1665348e-04, -6.8018347e-04, -4.2768568e-04, ...,\n",
              "         -4.8506754e-03,  3.3226188e-03,  4.1374587e-03],\n",
              "        [-1.2996551e-03,  5.2701854e-03, -3.9819949e-03, ...,\n",
              "         -4.3179388e-03,  1.8899553e-03,  1.6152458e-03],\n",
              "        [-1.4547580e-03,  1.9360664e-03, -3.3284067e-03, ...,\n",
              "          5.4130568e-03, -3.3861254e-03, -1.5118683e-03],\n",
              "        ...,\n",
              "        [ 4.4720760e-03,  3.0221017e-03, -2.6231704e-03, ...,\n",
              "         -7.8587118e-04, -1.1350496e-02, -6.9067598e-04],\n",
              "        [ 7.9988055e-03, -3.0039966e-03, -1.3056274e-03, ...,\n",
              "         -3.5905272e-03, -8.6583616e-03, -4.3489430e-03],\n",
              "        [ 2.5518818e-03, -2.7308068e-03, -5.0273410e-04, ...,\n",
              "         -4.5034410e-03, -9.0987759e-04,  7.6300185e-04]],\n",
              "\n",
              "       [[ 8.5073020e-03, -4.3776031e-03, -3.0807513e-04, ...,\n",
              "         -4.4109765e-03, -4.2687906e-03, -4.7781914e-03],\n",
              "        [ 2.7682246e-03, -4.3048966e-03, -8.9723733e-04, ...,\n",
              "          5.8652237e-03, -6.9889976e-03, -6.5780804e-03],\n",
              "        [ 9.7014790e-04, -5.1412485e-03, -2.0602248e-03, ...,\n",
              "          1.0731476e-02, -7.2319531e-03, -6.1852257e-03],\n",
              "        ...,\n",
              "        [ 1.2718141e-05,  4.9196240e-03,  3.1913442e-03, ...,\n",
              "          1.3035279e-03,  2.8821785e-04, -4.9440074e-04],\n",
              "        [ 8.2225236e-04,  2.0208468e-03,  2.5857280e-03, ...,\n",
              "         -5.5328514e-03,  4.7105057e-03,  4.0593971e-03],\n",
              "        [ 5.9609832e-03,  8.6962664e-04, -2.0639249e-03, ...,\n",
              "         -4.5768106e-03,  2.0314429e-03,  1.6373062e-03]],\n",
              "\n",
              "       [[ 8.1665348e-04, -6.8018347e-04, -4.2768568e-04, ...,\n",
              "         -4.8506754e-03,  3.3226188e-03,  4.1374587e-03],\n",
              "        [ 1.0607503e-03, -1.4193536e-03, -8.3294651e-04, ...,\n",
              "         -6.4695473e-03,  5.1788171e-03,  5.8232900e-03],\n",
              "        [ 9.1603957e-04, -1.9912974e-03, -1.1931165e-03, ...,\n",
              "         -6.7136441e-03,  6.3725449e-03,  6.4796158e-03],\n",
              "        ...,\n",
              "        [-4.7375646e-04,  3.1951526e-03, -3.6765095e-03, ...,\n",
              "          5.1095467e-03, -3.5288518e-03, -1.9540279e-03],\n",
              "        [ 8.6326087e-03, -3.3064710e-03, -3.0482514e-03, ...,\n",
              "         -1.1411532e-03, -5.2294573e-03, -4.5995163e-03],\n",
              "        [ 4.5094178e-03, -3.0322280e-03, -1.9253554e-03, ...,\n",
              "         -3.7724306e-03,  4.7806802e-04,  1.1983635e-03]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-2.2388475e-03, -9.0534799e-03, -1.0935232e-02, ...,\n",
              "         -5.1559806e-03,  3.8492992e-03,  5.6497562e-03],\n",
              "        [-2.2304719e-03, -1.5685331e-03, -5.8586132e-03, ...,\n",
              "          9.0248673e-04, -4.2202687e-03, -1.2050688e-03],\n",
              "        [ 2.1358603e-05, -1.2414251e-03, -4.2903568e-03, ...,\n",
              "         -3.7328633e-03,  1.9231981e-03,  4.8802355e-03],\n",
              "        ...,\n",
              "        [-1.8749007e-03,  3.5881372e-03, -4.6489048e-03, ...,\n",
              "          1.7845049e-04,  2.9764837e-03,  1.6510744e-03],\n",
              "        [-1.8049304e-03,  8.8215561e-04, -3.4963498e-03, ...,\n",
              "          8.2726078e-03, -2.4391210e-03, -1.3270288e-03],\n",
              "        [ 3.5734766e-04, -9.4743969e-04, -2.7470314e-03, ...,\n",
              "          3.8541167e-04,  3.0665435e-03,  4.7004218e-03]],\n",
              "\n",
              "       [[ 6.1672565e-04,  2.2789286e-03, -9.8973198e-04, ...,\n",
              "         -9.3488855e-04, -7.5471536e-03,  5.7017026e-03],\n",
              "        [ 7.2511565e-04,  1.4638211e-04, -8.6626381e-04, ...,\n",
              "         -6.4140065e-03, -4.8731896e-04,  7.3283412e-03],\n",
              "        [ 8.7009817e-03, -3.4423079e-03, -1.0886430e-03, ...,\n",
              "          2.9705110e-04, -5.6550950e-03, -1.1892139e-03],\n",
              "        ...,\n",
              "        [ 4.2495178e-04, -1.0857768e-03, -3.2400731e-03, ...,\n",
              "          1.6382332e-04,  2.7315998e-03,  5.5344505e-03],\n",
              "        [ 1.5062854e-03, -5.1530143e-03, -3.9833351e-03, ...,\n",
              "         -5.2527906e-03,  3.0621286e-03,  2.2306847e-03],\n",
              "        [ 7.4122325e-03, -1.4888807e-03, -6.5670880e-03, ...,\n",
              "         -4.9822093e-03, -5.7328688e-03, -2.3186870e-03]],\n",
              "\n",
              "       [[ 8.1665348e-04, -6.8018347e-04, -4.2768568e-04, ...,\n",
              "         -4.8506754e-03,  3.3226188e-03,  4.1374587e-03],\n",
              "        [-4.3141143e-03,  2.8406322e-04, -2.4918888e-03, ...,\n",
              "          2.5215964e-03,  4.3073669e-04, -4.6453471e-04],\n",
              "        [-2.6435205e-03, -1.8364282e-03, -1.6707828e-03, ...,\n",
              "          9.2279334e-03, -2.6296391e-03, -3.2062635e-03],\n",
              "        ...,\n",
              "        [ 1.2282371e-03, -3.8124858e-03,  5.9722457e-05, ...,\n",
              "         -1.8566725e-03,  3.7262328e-03, -1.5510956e-03],\n",
              "        [-1.6886354e-03, -5.2965856e-03, -7.0696948e-03, ...,\n",
              "         -8.1864176e-03,  5.3843721e-03, -1.2479064e-03],\n",
              "        [-5.1540076e-03, -1.1285974e-03, -9.7502051e-03, ...,\n",
              "         -6.9246558e-03, -7.2890618e-03, -4.2383736e-03]]], dtype=float32)>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_batch_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_achqjT-BGyY"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xWrPFk2nBJX4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(120, 1), dtype=int64, numpy=\n",
              "array([[57],\n",
              "       [45],\n",
              "       [33],\n",
              "       [67],\n",
              "       [69],\n",
              "       [25],\n",
              "       [39],\n",
              "       [14],\n",
              "       [65],\n",
              "       [65],\n",
              "       [62],\n",
              "       [37],\n",
              "       [33],\n",
              "       [76],\n",
              "       [30],\n",
              "       [29],\n",
              "       [32],\n",
              "       [14],\n",
              "       [71],\n",
              "       [62],\n",
              "       [47],\n",
              "       [ 0],\n",
              "       [66],\n",
              "       [13],\n",
              "       [36],\n",
              "       [40],\n",
              "       [49],\n",
              "       [39],\n",
              "       [76],\n",
              "       [50],\n",
              "       [65],\n",
              "       [ 2],\n",
              "       [10],\n",
              "       [30],\n",
              "       [19],\n",
              "       [19],\n",
              "       [20],\n",
              "       [37],\n",
              "       [62],\n",
              "       [18],\n",
              "       [11],\n",
              "       [71],\n",
              "       [24],\n",
              "       [71],\n",
              "       [ 2],\n",
              "       [81],\n",
              "       [31],\n",
              "       [32],\n",
              "       [37],\n",
              "       [ 1],\n",
              "       [31],\n",
              "       [36],\n",
              "       [56],\n",
              "       [17],\n",
              "       [ 4],\n",
              "       [44],\n",
              "       [44],\n",
              "       [11],\n",
              "       [33],\n",
              "       [ 2],\n",
              "       [79],\n",
              "       [30],\n",
              "       [37],\n",
              "       [48],\n",
              "       [57],\n",
              "       [35],\n",
              "       [38],\n",
              "       [48],\n",
              "       [72],\n",
              "       [20],\n",
              "       [39],\n",
              "       [67],\n",
              "       [55],\n",
              "       [38],\n",
              "       [19],\n",
              "       [35],\n",
              "       [50],\n",
              "       [38],\n",
              "       [56],\n",
              "       [16],\n",
              "       [14],\n",
              "       [19],\n",
              "       [39],\n",
              "       [47],\n",
              "       [73],\n",
              "       [52],\n",
              "       [12],\n",
              "       [ 8],\n",
              "       [15],\n",
              "       [ 9],\n",
              "       [ 0],\n",
              "       [ 8],\n",
              "       [71],\n",
              "       [73],\n",
              "       [11],\n",
              "       [35],\n",
              "       [61],\n",
              "       [36],\n",
              "       [39],\n",
              "       [11],\n",
              "       [48],\n",
              "       [27],\n",
              "       [62],\n",
              "       [43],\n",
              "       [ 8],\n",
              "       [55],\n",
              "       [14],\n",
              "       [22],\n",
              "       [ 7],\n",
              "       [49],\n",
              "       [23],\n",
              "       [47],\n",
              "       [44],\n",
              "       [37],\n",
              "       [46],\n",
              "       [33],\n",
              "       [43],\n",
              "       [ 1],\n",
              "       [ 4],\n",
              "       [ 2]])>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Wi80PQVtBLqj"
      },
      "outputs": [],
      "source": [
        "# Reformat to not be a lists of lists\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4qYkIg00-wjq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([57, 45, 33, 67, 69, 25, 39, 14, 65, 65, 62, 37, 33, 76, 30, 29, 32,\n",
              "       14, 71, 62, 47,  0, 66, 13, 36, 40, 49, 39, 76, 50, 65,  2, 10, 30,\n",
              "       19, 19, 20, 37, 62, 18, 11, 71, 24, 71,  2, 81, 31, 32, 37,  1, 31,\n",
              "       36, 56, 17,  4, 44, 44, 11, 33,  2, 79, 30, 37, 48, 57, 35, 38, 48,\n",
              "       72, 20, 39, 67, 55, 38, 19, 35, 50, 38, 56, 16, 14, 19, 39, 47, 73,\n",
              "       52, 12,  8, 15,  9,  0,  8, 71, 73, 11, 35, 61, 36, 39, 11, 48, 27,\n",
              "       62, 43,  8, 55, 14, 22,  7, 49, 23, 47, 44, 37, 46, 33, 43,  1,  4,\n",
              "        2])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "H9-P_XqQ_7wY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Given the input seq: \n",
            "\n",
            " heart.\n",
            "    She soon shall know of us, by some of ours,\n",
            "    How honourable and how kindly we\n",
            "    Determine for her; for \n",
            "\n",
            "\n",
            "Next Char Predictions: \n",
            "\n",
            "bTHln?N3jjgLHuEDG3pgV\n",
            "k2KOXNuYj!.E889Lg70p>p!zFGL FKa6&SS0H!xELWbJMWq9Nl`M8JYMa538NVr[1,4-\n",
            ",pr0JfKN0WBgR,`3;)X<VSLUHR &!\n"
          ]
        }
      ],
      "source": [
        "print(\"Given the input seq: \\n\")\n",
        "print(\"\".join(ind_to_char[input_example_batch[0]]))\n",
        "print('\\n')\n",
        "print(\"Next Char Predictions: \\n\")\n",
        "print(\"\".join(ind_to_char[sampled_indices ]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DAOE4rzuBh7f"
      },
      "source": [
        "After confirming the dimensions are working, let's train our network!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ZYDQjKTlm4s8"
      },
      "outputs": [],
      "source": [
        "epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_PJ4OVdBm4s8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "  2/351 [..............................] - ETA: 1:08:01 - loss: 4.3762"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/maneesh/Desktop/tf/TF_2_Notebooks_and_Data/06-NLP-and-Text-Data/00_Generating_Text.ipynb Cell 39\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/maneesh/Desktop/tf/TF_2_Notebooks_and_Data/06-NLP-and-Text-Data/00_Generating_Text.ipynb#Y153sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mfit(dataset,epochs\u001b[39m=\u001b[39mepochs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mconcrete_function\u001b[39m.\u001b[39mcaptured_inputs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inference_function\u001b[39m.\u001b[39mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.fit(dataset,epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "eYRNG57Govdc"
      },
      "outputs": [],
      "source": [
        "model.save('shakespeare_gen.h5') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GCoJayFS8H4d"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_iXG3VJvEXWM"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-16 13:56:22.525305: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-09-16 13:56:22.527228: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-09-16 13:56:22.528884: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
          ]
        }
      ],
      "source": [
        "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n",
        "\n",
        "model.load_weights('shakespeare_gen.h5')\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LAX3p7_YEilU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (1, None, 64)             5376      \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (1, None, 1026)           3361176   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (1, None, 84)             86268     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,452,820\n",
            "Trainable params: 3,452,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WvuwZBX5Ogfd"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, start_seed,gen_size=100,temp=1.0):\n",
        "  num_generate = gen_size\n",
        "  input_eval = [char_to_ind[s] for s in start_seed]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "  text_generated = []\n",
        "  temperature = temp\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "\n",
        "      predictions = model(input_eval)\n",
        "\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "\n",
        "      text_generated.append(ind_to_char[predicted_id])\n",
        "\n",
        "  return (start_seed + ''.join(text_generated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "bS69SG5D5lwd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "flower<2!hHm S3T1|]UHE 6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n"
          ]
        }
      ],
      "source": [
        "print(generate_text(model,\"flower\",gen_size=1000))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "00-Generating-Text-with-RNNs.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
